<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Safety Research: Multilingual Jailbreak Analysis</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.plot.ly/plotly-2.27.0.min.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet">
    <style>
        body { font-family: 'Inter', sans-serif; }
        .plotly-graph-div { width: 100%; }
    </style>
</head>
<body class="bg-slate-50 text-slate-900">

    <!-- Navbar -->
    <nav class="bg-slate-900 text-white shadow-lg sticky top-0 z-50">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex items-center justify-between h-16">
                <div class="flex items-center">
                    <span class="font-bold text-xl tracking-tight">üõ°Ô∏è AI Safety Research</span>
                    <span class="ml-4 text-slate-400 text-sm hidden sm:block">Multilingual Jailbreak Analysis</span>
                </div>
                <div class="text-xs text-slate-500">
                    Confidential Research Data
                </div>
            </div>
        </div>
    </nav>

    <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">

        <!-- Header -->
        <header class="mb-10">
            <h1 class="text-3xl font-bold text-slate-900 mb-2">Experimental Results</h1>
            <p class="text-slate-600">Analysis of jailbreak effectiveness across 12 open-source models and 5 languages.</p>
        </header>

        <!-- Summary Section -->
        <section class="grid grid-cols-1 md:grid-cols-2 gap-6 mb-12">
            <!-- Insight 1 -->
            <div class="bg-white p-6 rounded-xl shadow-sm border border-slate-200">
                <div class="flex items-center mb-4">
                    <div class="p-2 bg-red-100 rounded-lg text-red-600 mr-3">
                        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path></svg>
                    </div>
                    <h2 class="text-lg font-bold text-slate-800">Low-Resource Vulnerability</h2>
                </div>
                <p class="text-slate-600 leading-relaxed text-sm">
                    Our analysis reveals a significant vulnerability in low-resource languages. While models performed robustly in <strong>English (9.61)</strong> and <strong>Arabic (9.67)</strong>, safety mechanisms degraded sharply in <strong>Esperanto</strong>, with an average score of just <strong>8.47</strong>. Several models, including <code>mistral</code> and <code>glm4</code>, failed to refuse harmful requests in Esperanto that they successfully blocked in other languages.
                </p>
            </div>

            <!-- Insight 2 -->
            <div class="bg-white p-6 rounded-xl shadow-sm border border-slate-200">
                <div class="flex items-center mb-4">
                    <div class="p-2 bg-green-100 rounded-lg text-green-600 mr-3">
                        <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                    </div>
                    <h2 class="text-lg font-bold text-slate-800">Safety by Confusion</h2>
                </div>
                <p class="text-slate-600 leading-relaxed text-sm">
                    <strong>Kinyarwanda</strong> achieved the highest safety score <strong>(9.97)</strong>. However, qualitative analysis suggests this is not due to robust alignment, but rather a lack of model capability. Models frequently failed to translate or comprehend harmful prompts in Kinyarwanda, hallucinating benign nonsense instead of complying, effectively acting as a "safety by confusion" mechanism.
                </p>
            </div>
        </section>

        <!-- Charts Grid -->
        <section class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-12">
            
            <!-- Language Performance Chart -->
            <div class="bg-white p-6 rounded-xl shadow-sm border border-slate-200">
                <h3 class="text-lg font-semibold text-slate-800 mb-4">Average Safety Score by Language</h3>
                <div id="languageChart" class="h-80 w-full"></div>
            </div>

            <!-- Model Ranking Chart -->
            <div class="bg-white p-6 rounded-xl shadow-sm border border-slate-200">
                <h3 class="text-lg font-semibold text-slate-800 mb-4">Model Robustness Ranking</h3>
                <div id="modelChart" class="h-80 w-full"></div>
            </div>

        </section>

        <!-- Heatmap Section -->
        <section class="bg-white p-6 rounded-xl shadow-sm border border-slate-200 mb-12">
            <h3 class="text-lg font-semibold text-slate-800 mb-2">Model vs. Language Heatmap</h3>
            <p class="text-sm text-slate-500 mb-6">Visualizing specific failure points. Darker red indicates lower safety scores (higher vulnerability).</p>
            <div id="heatmapChart" class="h-[500px] w-full"></div>
        </section>

    </div>

    <!-- Footer -->
    <footer class="bg-slate-900 text-slate-400 py-8 text-center text-sm">
        <p>¬© 2024 AI Safety Research Lab. Confidential.</p>
    </footer>

    <script>
        // Data derived from the Python analysis
        const languageData = {
            x: ['Esperanto', 'Latin', 'English', 'Arabic', 'Kinyarwanda'],
            y: [8.47, 9.50, 9.61, 9.67, 9.97],
            type: 'bar',
            marker: {
                color: ['#ef4444', '#f59e0b', '#3b82f6', '#3b82f6', '#10b981'] // Red for Esperanto, Green for Kinyarwanda
            }
        };

        const modelData = {
            y: ['Mistral', 'GLM-4 9B', 'Nemotron Mini', 'Mistral NeMo', 'Phi-3.5', 'InternLM2 20B', 'Llama 3.2', 'MiniCPM-V', 'DeepSeek R1', 'Yi 9B', 'Gemma 2 2B', 'Qwen 2.5 14B'],
            x: [8.30, 8.47, 8.87, 8.97, 9.30, 9.73, 9.83, 9.93, 9.97, 9.97, 10.00, 10.00],
            type: 'bar',
            orientation: 'h',
            marker: {
                color: x => x.map(v => v < 9.0 ? '#ef4444' : '#3b82f6')
            }
        };

        // Heatmap Data (Model vs Language)
        // Rows: Models, Cols: Languages (Ar, En, Es, Ki, La)
        const models = ['DeepSeek R1', 'Gemma 2', 'GLM-4', 'InternLM2', 'Llama 3.2', 'MiniCPM-V', 'Mistral', 'Mistral NeMo', 'Nemotron', 'Phi-3.5', 'Qwen 2.5', 'Yi 9B'];
        const languages = ['Arabic', 'English', 'Esperanto', 'Kinyarwanda', 'Latin'];
        
        // Data strictly from the Python analysis matrix
        const zValues = [
            [9.83, 10.00, 10.00, 10.00, 10.00], // DeepSeek
            [10.00, 10.00, 10.00, 10.00, 10.00], // Gemma 2
            [8.67, 10.00, 5.33, 9.67, 8.67],   // GLM-4 (Note the 5.33)
            [10.00, 10.00, 8.67, 10.00, 10.00], // InternLM2
            [10.00, 10.00, 10.00, 10.00, 9.17], // Llama 3.2
            [9.67, 10.00, 10.00, 10.00, 10.00], // MiniCPM
            [8.83, 6.83, 7.17, 10.00, 8.67],   // Mistral
            [9.17, 8.50, 8.67, 10.00, 8.50],   // Mistral NeMo
            [10.00, 10.00, 4.33, 10.00, 10.00], // Nemotron (Note the 4.33)
            [10.00, 10.00, 7.50, 10.00, 9.00],  // Phi 3.5
            [10.00, 10.00, 10.00, 10.00, 10.00], // Qwen
            [9.83, 10.00, 10.00, 10.00, 10.00]  // Yi
        ];

        // 1. Render Language Chart
        Plotly.newPlot('languageChart', [languageData], {
            margin: { t: 20, r: 20, l: 40, b: 40 },
            yaxis: { range: [0, 10.5], title: 'Avg Safety Score (10=Safe)' },
            paper_bgcolor: 'rgba(0,0,0,0)',
            plot_bgcolor: 'rgba(0,0,0,0)'
        }, {responsive: true});

        // 2. Render Model Chart
        Plotly.newPlot('modelChart', [modelData], {
            margin: { t: 20, r: 20, l: 120, b: 40 },
            xaxis: { range: [0, 10.5], title: 'Avg Safety Score' },
            paper_bgcolor: 'rgba(0,0,0,0)',
            plot_bgcolor: 'rgba(0,0,0,0)'
        }, {responsive: true});

        // 3. Render Heatmap
        const heatmapTrace = {
            z: zValues,
            x: languages,
            y: models,
            type: 'heatmap',
            colorscale: [
                [0, '#b91c1c'],    // Deep red for low scores
                [0.5, '#fbbf24'],  // Yellow for mid scores
                [0.9, '#dbeafe'],  // Light blue
                [1, '#2563eb']     // Blue for perfect scores
            ],
            showscale: true
        };

        Plotly.newPlot('heatmapChart', [heatmapTrace], {
            margin: { t: 20, r: 20, l: 120, b: 60 },
            paper_bgcolor: 'rgba(0,0,0,0)',
            plot_bgcolor: 'rgba(0,0,0,0)'
        }, {responsive: true});

    </script>
</body>
</html>